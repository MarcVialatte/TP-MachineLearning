{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935fa367-02fc-4b31-a289-41fd8ee04a9f",
   "metadata": {},
   "source": [
    "# TP 3 - Evaluation des systèmes d’Intelligence Artificielle\n",
    "\n",
    "\n",
    "## 0.1 Description de la tâche réalisée par votre modèle\n",
    "\n",
    "La tâche réalisée par le modèle est la classification des émotions dans des commentaires.\n",
    "Plus précisément, le modèle utilise un ensemble de données qui comprend des commentaires (contenus dans la colonne 'Comment') \n",
    "et des étiquettes d'émotions correspondantes (contenues dans la colonne 'Emotion'). \n",
    "Le modèle utilise ces données pour entraîner un classificateur Randomforest basé sur la représentation TF-IDF des phrases.\n",
    "\n",
    "\n",
    "## 0.2 Procédure d’évaluation\n",
    "\n",
    "La procédure d'évaluation comprend plusieurs étapes :\n",
    "\n",
    "+ Chargement des données : Les données sont chargées à partir du fichier CSV (\"emotion_classify_dataset.csv\").\n",
    " + Division des données : Les données sont divisées en ensembles d'entraînement et de test à l'aide de la fonction train_test_split de scikit-learn. 80% des données sont utilisées pour l'entraînement et 20% pour les tests.\n",
    "+ Création de vecteurs TF-IDF : Les commentaires sont transformés en vecteurs TF-IDF à l'aide de la classe TfidfVectorizer de scikit-learn.\n",
    "+ Entraînement du modèle : Un modèle de forêt aléatoire est créé et entraîné sur les vecteurs TF-IDF de l'ensemble d'entraînement.\n",
    "+ Prédiction : Les émotions sont prédites sur l'ensemble de test à l'aide du modèle entraîné.\n",
    "+ Évaluation des performances : La précision (accuracy) et d'autres métriques sont calculées à l'aide de accuracy_score et classification_report de scikit-learn.\n",
    "\n",
    "## 0.3 Identification des facteurs d’influence\n",
    "\n",
    "Les facteurs d'influence potentiels sur la performance du modèle pourraient inclure :\n",
    "\n",
    "- La qualité et la représentativité des données d'entraînement.\n",
    "- Le choix du modèle (forêt aléatoire) et de ses hyperparamètres (nombre d'estimateurs, etc.).\n",
    "- La représentation TF-IDF des phrases et les paramètres associés (max_features, stop_words, etc.).\n",
    "\n",
    "## 0.4 Définition des métriques\n",
    "\n",
    "Les métriques utilisées pour évaluer le modèle sont la précision (accuracy) et le rapport de classification (classification_report).\n",
    "\n",
    "- **Accuracy :** Mesure la proportion de prédictions correctes par rapport au nombre total de prédictions.\n",
    "\n",
    "- **Classification Report :** Fournit des métriques détaillées telles que la précision, le rappel et le score F1 pour chaque classe, ainsi que la moyenne globale. Cela donne une vision plus détaillée de la performance du modèle par classe.\n",
    "\n",
    "\n",
    "## 0.5 Échantillonnage\n",
    "\n",
    "Quantité de données :\n",
    "\n",
    "- Il est décidé d'utiliser 80% des données pour l'ensemble d'apprentissage et 20% pour l'ensemble d'évaluation.\n",
    "\n",
    "Facteurs d'influence pour construire les corpus :\n",
    "\n",
    "- Les principaux facteurs d'influence pour la construction des corpus peuvent inclure la répartition des émotions dans les données, la diversité des commentaires, et l'équilibre entre les classes.\n",
    "\n",
    "Facteurs critiques :\n",
    "\n",
    "- L'équilibre entre les émotions dans les deux ensembles (apprentissage et évaluation) est critique pour garantir que le modèle est exposé à une variété suffisante de situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7ce4b",
   "metadata": {},
   "source": [
    "## 0.6 Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b154b153-e805-4111-9270-cffc9d4d1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data = pd.read_csv(\"emotion_classify_dataset.csv\")\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data['Comment'], data['Emotion'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c14a9",
   "metadata": {},
   "source": [
    "## 0.7 Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe7c502-cb97-4d97-adfb-42ef72bf06ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5456e6b",
   "metadata": {},
   "source": [
    "## 0.8 Évaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842eedf9-48a2-4d1d-ab28-8679a61ea419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Evaluation Set: 0.946969696969697\n",
      "Classification Report on Evaluation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.93      0.94      0.94       392\n",
      "        fear       0.97      0.93      0.95       416\n",
      "         joy       0.94      0.97      0.95       380\n",
      "\n",
      "    accuracy                           0.95      1188\n",
      "   macro avg       0.95      0.95      0.95      1188\n",
      "weighted avg       0.95      0.95      0.95      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_vectors = vectorizer.transform(test_data)\n",
    "evaluation_predictions = classifier.predict(evaluation_vectors)\n",
    "\n",
    "evaluation_accuracy = accuracy_score(test_labels, evaluation_predictions)\n",
    "classification_rep_evaluation = classification_report(test_labels, evaluation_predictions)\n",
    "\n",
    "print(f\"Accuracy on Evaluation Set: {evaluation_accuracy}\")\n",
    "print(\"Classification Report on Evaluation Set:\\n\", classification_rep_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d9a78-658d-4c99-8fda-944bcb342bec",
   "metadata": {},
   "source": [
    "## 0.9 Identification des bruits\n",
    "\n",
    "Les bruits potentiels dans les données textuelles peuvent inclure :\n",
    "\n",
    "- Fautes d'orthographe intentionnelles.\n",
    "- Ajout de mots inutiles.\n",
    "- Suppression de mots clés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a3129",
   "metadata": {},
   "source": [
    "## 0.10 Génération de données bruitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441f6cde-ca76-4f50-83d9-98e08d3839a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def add_spelling_mistake(text):\n",
    "    return text.replace(\"good\", \"goood\")\n",
    "\n",
    "def add_random_words(text):\n",
    "    return text + \" random_word1 random_word2\"\n",
    "\n",
    "\n",
    "noisy_test_data = test_data.apply(add_spelling_mistake)\n",
    "noisy_test_data = noisy_test_data.apply(add_random_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4ff6a",
   "metadata": {},
   "source": [
    "## 0.11 Évaluation de la performance sur le corpus bruité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26324462-ee47-425a-8e86-f7f24330df4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Noisy Evaluation Set: 0.9478114478114478\n",
      "Classification Report on Noisy Evaluation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.93      0.95      0.94       392\n",
      "        fear       0.97      0.93      0.95       416\n",
      "         joy       0.95      0.97      0.96       380\n",
      "\n",
      "    accuracy                           0.95      1188\n",
      "   macro avg       0.95      0.95      0.95      1188\n",
      "weighted avg       0.95      0.95      0.95      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noisy_evaluation_vectors = vectorizer.transform(noisy_test_data)\n",
    "\n",
    "noisy_evaluation_predictions = classifier.predict(noisy_evaluation_vectors)\n",
    "\n",
    "noisy_evaluation_accuracy = accuracy_score(test_labels, noisy_evaluation_predictions)\n",
    "classification_rep_noisy_evaluation = classification_report(test_labels, noisy_evaluation_predictions)\n",
    "\n",
    "print(f\"Accuracy on Noisy Evaluation Set: {noisy_evaluation_accuracy}\")\n",
    "print(\"Classification Report on Noisy Evaluation Set:\\n\", classification_rep_noisy_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
